{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajni-arora/Deep-Learning-Projects/blob/main/Bert_tokenizer(Multiclass%20Problem)Sentiment%20classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMRkIFhuTM9M"
      },
      "source": [
        "# Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76HfPILdC5lD"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1h4YVFfDd1t",
        "outputId": "741da000-0070-44b5-f62b-3e0e7415de26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 131 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=bbaefd4bc7cb6f6a7eb4c2edc78d68cadb42afe59a2cf40934e40f8acba27f13\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19473 sha256=0e059e6eb69448154a2b73a5f18b4255d50c1e83d284abe59fbf0d6b3f7b7833\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7912 sha256=439f82e800f94ef81599c5c35c570c8e10ae8cc0fbf71595c90c3a121363d5c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 12.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMqTwu9jENrO"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_xu0I3jFP9"
      },
      "source": [
        "# Stage 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FifCe97pTVql"
      },
      "source": [
        "## Loading files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S0lOeu8TbnP"
      },
      "source": [
        "We import files from our personal Google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6iT5nxDHLRz"
      },
      "source": [
        "cols = [\"Class\", \"Cleaned_Text\"]\n",
        "\n",
        "data = pd.read_csv(\n",
        "    '/content/sample_data/processed_data.csv',\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKnCVewUIBkc"
      },
      "source": [
        "# data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
        "#           axis=1,\n",
        "#           inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWWUo_XVeqoG",
        "outputId": "882cf1b2-a8cb-496e-c0c6-eda4ad922851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Cleaned_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vaccine Challenges</td>\n",
              "      <td>faints from mild pain by the way a ton of girl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vaccine Challenges</td>\n",
              "      <td>painislife said not saying that is not the cas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Consumer Experience</td>\n",
              "      <td>goldenwolf87 said i wonder how much more commo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Consumer Experience</td>\n",
              "      <td>travelnomad said hpv herpes can be contracted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Consumer Experience</td>\n",
              "      <td>louisiana fisher said im sitting there playing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Consumer Experience</td>\n",
              "      <td>wonder if there is a link between miss and hpv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Consumer Experience</td>\n",
              "      <td>hpv has not been linked to developing miss pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Consumer Experience</td>\n",
              "      <td>hi i m mason i got this lump on penile shaft a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Consumer Experience</td>\n",
              "      <td>be reddish in color or white sometimes you can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Vaccine Challenges</td>\n",
              "      <td>hours to get through gardasil even causes canc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Class                                       Cleaned_Text\n",
              "1    Vaccine Challenges  faints from mild pain by the way a ton of girl...\n",
              "2    Vaccine Challenges  painislife said not saying that is not the cas...\n",
              "3   Consumer Experience  goldenwolf87 said i wonder how much more commo...\n",
              "4   Consumer Experience  travelnomad said hpv herpes can be contracted ...\n",
              "5   Consumer Experience  louisiana fisher said im sitting there playing...\n",
              "6   Consumer Experience  wonder if there is a link between miss and hpv...\n",
              "7   Consumer Experience  hpv has not been linked to developing miss pla...\n",
              "8   Consumer Experience  hi i m mason i got this lump on penile shaft a...\n",
              "9   Consumer Experience  be reddish in color or white sometimes you can...\n",
              "10   Vaccine Challenges  hours to get through gardasil even causes canc..."
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry9s0HRV7gQe"
      },
      "source": [
        "data = data[1:]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Quzx5tnjUtl"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8hlexmRjXIS"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBSUDL-UP-W_"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    # Delete the @\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    # Delete URL links\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    # Just keep letters and important punctuation\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    # Remove additional spaces\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jiMaQsLWiTS"
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.Cleaned_Text.astype(str)]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXcaZzud7FVK",
        "outputId": "2ce1e17f-8824-40e9-bbfa-3e3e83252202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data[\"Class\"].value_counts()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Consumer Experience     7454\n",
              "HPV Screening           5356\n",
              "Awareness Related       2136\n",
              "Vaccine Challenges      1732\n",
              "Others                   940\n",
              "Study Results            475\n",
              "Campaign_initiatives     190\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpp7U2f87oMZ"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SeSuSTP767c"
      },
      "source": [
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(data[\"Class\"])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_huNMCvx8DUM",
        "outputId": "31db1d48-40b0-4cdb-b60e-dfe909a94e5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels[:100]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 0, 0, 3, 1, 2, 2, 2, 6, 2, 0, 2, 2,\n",
              "       3, 3, 2, 3, 2, 3, 6, 2, 2, 2, 2, 3, 2, 0, 3, 2, 2, 3, 3, 3, 2, 3,\n",
              "       3, 3, 2, 2, 2, 0, 6, 6, 2, 2, 3, 2, 4, 2, 3, 2, 3, 3, 3, 2, 3, 3,\n",
              "       2, 3, 0, 2, 3, 2, 2, 2, 5, 2, 2, 2, 0, 0, 0, 2, 6, 2, 0, 2, 2, 2,\n",
              "       2, 3, 2, 2, 2, 3, 3, 3, 2, 3, 2, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaqLE0fdWtni"
      },
      "source": [
        "# data_labels = data.Class.values\n",
        "# data_labels[data_labels == 4] = 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eh7sIquja5t"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV73IkgKUCmV"
      },
      "source": [
        "We need to create a BERT layer to have access to meta data for the tokenizer (like vocab size)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP9DDxDkq4-n"
      },
      "source": [
        "input = 'Where are you going?'\n",
        "output = ['where', 'are', 'you', 'going', '?']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wry-st-HMN0"
      },
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LggMv7k7Z3Ij"
      },
      "source": [
        "def encode_sentence(sent):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5izCrwmtNwL"
      },
      "source": [
        "**encode_sentence** = Universal Sentence Encoder encodes entire sentence or text into vectors of real numbers that can be used for clustering, sentence similarity, text classification, and other Natural language processing (NLP) tasks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGfTo5uIa2is"
      },
      "source": [
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nubUeffsrGuS"
      },
      "source": [
        "data_inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-4oGSu5jxUi"
      },
      "source": [
        "### Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaVPF9-rUTqZ"
      },
      "source": [
        "We will create padded batches (so we pad sentences for each batch inpedendently), this way we add the minimum of padding tokens possible. For that, we sort sentences by length, apply padded_batches and then shuffle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS_f6gWsLfLM"
      },
      "source": [
        "data_with_len = [[sent, labels[i], len(sent)] for i, sent in enumerate(data_inputs)]\n",
        "random.shuffle(data_with_len)\n",
        "data_with_len.sort(key=lambda x: x[2])\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qADyNsgz8RsS"
      },
      "source": [
        "sorted_all = [(sent_lab[0], sent_lab[1])\n",
        "              for sent_lab in data_with_len if sent_lab[2] >10]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0uJJg8lSQR"
      },
      "source": [
        "# A list is a type of iterator so it can be used as generator for a dataset\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32,tf.int32))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQKqLuIet1V1",
        "outputId": "64a3b10f-9d84-46b1-f45e-3e4d838b5bfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "all_dataset"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FlatMapDataset shapes: (<unknown>,), types: (tf.int32,)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF74g5hpYzaZ",
        "outputId": "96318d3f-c170-4c3b-9ef0-5e8471b655ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(11,), dtype=int32, numpy=\n",
              " array([2613, 4485, 6522, 2615, 1998, 2060, 4485, 7110, 2102, 2053, 8257],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHAhlfTlrcj"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ktdxCEm4Yh",
        "outputId": "0d27a417-e9a8-4293-c23d-075eb325358d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 11), dtype=int32, numpy=\n",
              " array([[ 2613,  4485,  6522,  2615,  1998,  2060,  4485,  7110,  2102,\n",
              "          2053,  8257],\n",
              "        [ 2054,  2015,  2008,  1998,  2054,  1998,  2043,  2003,  1996,\n",
              "          6643,  2361],\n",
              "        [ 2498,  2066,  2893,  1037,  6643,  2361, 15488, 14644,  2039,\n",
              "          2115,  4451],\n",
              "        [ 4756,  2026,  8239,  4632,  2125,  2157,  2066,  2017,  2525,\n",
              "          2253,  5742],\n",
              "        [ 2129,  2106,  2017,  2131,  2009,  3718,  2129,  2146,  2106,\n",
              "          2009,  2202],\n",
              "        [10413, 22911,  2053,  1045,  2031,  2025,  2018,  1996,  6522,\n",
              "          2615, 17404],\n",
              "        [ 2061,  2024,  2122, 14148,  2066,  2893,  1037,  6643,  2361,\n",
              "         15488, 14644],\n",
              "        [ 2033,  2043,  2049,  2051,  2005,  2026, 12142,  6643,  2361,\n",
              "         15488, 14644],\n",
              "        [ 1998,  2025,  2069, 28896,  2644, 13475,  2006,  2502, 21890,\n",
              "         17830, 10338],\n",
              "        [10166,  2035,  2013,  1037, 17404,  3745,  2014,  2466,  2023,\n",
              "          3532,  2611],\n",
              "        [ 2008,  2003,  2525,  2018,  1037,  6643,  2361,  1998,  2053,\n",
              "          2558,  2664],\n",
              "        [ 1045,  2288,  2026, 19857,  2915,  1998,  2117,  6522,  2615,\n",
              "         17404,  2651],\n",
              "        [ 1045,  2066,  2129,  2012,  1996,  3953,  2027,  4045,  3973,\n",
              "          2360,  7743],\n",
              "        [ 2036,  6456,  3531,  2131,  2115,  6643,  2361, 15488, 14644,\n",
              "          2296,  2095],\n",
              "        [ 5107,  6630,  1997,  2033,  2893,  2026,  2034,  6643,  2361,\n",
              "         15488, 14644],\n",
              "        [ 2026,  2303,  2003,  2025,  2635,  2023,  6522,  2615,  2915,\n",
              "          2200,  2092],\n",
              "        [27112,  3207, 10230,  2232,  2308, 12436, 14693, 23854,  2114,\n",
              "          6522,  2615],\n",
              "        [ 2192,  2705,  6824,  2100, 26227,  1045,  2288,  1037,  6522,\n",
              "          2615,  2915],\n",
              "        [ 2031,  2017,  5115,  2115,  6643,  2361, 15488, 14644,  2005,\n",
              "          2279,  2095],\n",
              "        [ 2909,  2079,  2017,  2113,  2129,  1037,  6643,  2361, 15488,\n",
              "         14644,  2573],\n",
              "        [ 2115,  2063,  3039,  2000,  2695,  1998,  1045,  2572,  3039,\n",
              "          2000,  7615],\n",
              "        [ 3524,  1045,  2123,  2102,  2123,  2102,  3305,  2129,  2000,\n",
              "          2079,  2008],\n",
              "        [27116,  5856,  5289,  3207,  2102,  2131,  1037,  6643,  2361,\n",
              "         15488, 14644],\n",
              "        [ 2079,  2273,  2131, 12436, 14693, 23854,  2005,  6522,  2615,\n",
              "          2027,  2323],\n",
              "        [ 1045,  2031,  1037,  2775,  2214,  2438,  2005,  2019,  6522,\n",
              "          2615, 17404],\n",
              "        [ 4067,  2017,  2061,  2172,  2017,  2031,  2428,  2039, 18412,\n",
              "          2098,  2033],\n",
              "        [ 2065,  2017,  3726,  2412,  2018,  3348,  2017,  2525,  2031,\n",
              "          6522,  2615],\n",
              "        [ 2502,  5874,  3676,  5910,  1045,  2018,  1037,  6643,  2361,\n",
              "         15488, 14644],\n",
              "        [ 2062,  2111,  2031,  6522,  2615,  2084,  2522, 17258,  5870,\n",
              "          2041,  5189],\n",
              "        [ 2633,  2288,  2026,  2197,  6522,  2615, 17404,  2589,  2007,\n",
              "          2008,  4485],\n",
              "        [ 1045,  2288,  2035,  1996,  6522,  2615, 17404,  2040,  2180,\n",
              "          2102,  2033],\n",
              "        [ 2852, 27178,  2863,  2863,  3067,  2001, 11721, 13639, 27572,\n",
              "          2196,  5293]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 4, 3, 2, 2, 4, 3, 3, 6, 6, 3, 2, 6, 3, 3, 2, 0, 4, 3, 3, 2, 4,\n",
              "        4, 0, 0, 2, 0, 4, 2, 2, 2, 6], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPqJeYpmfcv"
      },
      "source": [
        "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxONsFVHkFLU"
      },
      "source": [
        "# Stage 3: Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6DD3k3qPLDQ"
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 emb_dim=128,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=7,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"dcnn\"):\n",
        "        super(DCNN, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size,\n",
        "                                          emb_dim)\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 7:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"softmax\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "        x_1 = self.bigram(x) # (batch_size, nb_filters, seq_len-1)\n",
        "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
        "        x_2 = self.trigram(x) # (batch_size, nb_filters, seq_len-2)\n",
        "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
        "        x_3 = self.fourgram(x) # (batch_size, nb_filters, seq_len-3)\n",
        "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSix1l4jkIxp"
      },
      "source": [
        "# Stage 4: Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhfUFvWEPOIf"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 7\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtdiWmwv6rD"
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
        "            emb_dim=EMB_DIM,\n",
        "            nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apbd7FrwPYo"
      },
      "source": [
        "if NB_CLASSES == 7:\n",
        "    Dcnn.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78cceSGCw1XC",
        "outputId": "f0a854f1-0ac8-4db5-bf94-2e678cc9fad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint_path = \"./drive/MyDrive/projects/BERT/ckpt_bert_tok/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest Checkpoint restored!\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest Checkpoint restored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YIF5trzx7RA"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrT8oWZzQNmW",
        "outputId": "d3490de4-bcb2-4c25-d312-58457db100a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Dcnn.fit(train_dataset,\n",
        "         epochs=NB_EPOCHS,\n",
        "         callbacks=[MyCustomCallback()])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "485/485 [==============================] - 34s 67ms/step - loss: 0.0000e+00 - accuracy: 0.0111\n",
            "Checkpoint saved at ./drive/MyDrive/projects/BERT/ckpt_bert_tok/.\n",
            "Epoch 2/5\n",
            "485/485 [==============================] - 33s 67ms/step - loss: 0.0000e+00 - accuracy: 0.0111\n",
            "Checkpoint saved at ./drive/MyDrive/projects/BERT/ckpt_bert_tok/.\n",
            "Epoch 3/5\n",
            "485/485 [==============================] - 33s 68ms/step - loss: 0.0000e+00 - accuracy: 0.0111\n",
            "Checkpoint saved at ./drive/MyDrive/projects/BERT/ckpt_bert_tok/.\n",
            "Epoch 4/5\n",
            "485/485 [==============================] - 33s 67ms/step - loss: 0.0000e+00 - accuracy: 0.0111\n",
            "Checkpoint saved at ./drive/MyDrive/projects/BERT/ckpt_bert_tok/.\n",
            "Epoch 5/5\n",
            "485/485 [==============================] - 33s 67ms/step - loss: 0.0000e+00 - accuracy: 0.0111\n",
            "Checkpoint saved at ./drive/MyDrive/projects/BERT/ckpt_bert_tok/.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20ab614b10>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IiDW919kQQK"
      },
      "source": [
        "# Stage 5: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MthhNfnG1TPV",
        "outputId": "a951930a-350c-4654-c91b-ffcc16caaf32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0000e+00 - accuracy: 0.0065\n",
            "[0.0, 0.006485849153250456]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jrRvtl1xuk"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "    tokens = encode_sentence(sentence)\n",
        "    inputs = tf.expand_dims(tokens, 0)\n",
        "\n",
        "    output = Dcnn(inputs, training=False)\n",
        "\n",
        "    sentiment = math.floor(output*2)\n",
        "\n",
        "    if sentiment == 0:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: Awareness Related.\".format(\n",
        "            output))\n",
        "    elif sentiment == 1:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: Campaign_initiatives\t.\".format(\n",
        "            output))\n",
        "    elif sentiment == 2:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: Consumer Experience\t.\".format(\n",
        "            output))\n",
        "    elif sentiment == 3:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: HPV Screening.\".format(\n",
        "            output))\n",
        "    elif sentiment == 4:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: Others.\".format(\n",
        "            output))\n",
        "    elif sentiment == 5:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: Study Results.\".format(\n",
        "            output))\n",
        "    elif sentiment == 6:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: Vaccine Challenges.\".format(\n",
        "            output))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk8V2bdvwfCv",
        "outputId": "adcad938-e299-4a27-d475-0a31b98323d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_prediction(\"louisiana fisher said im sitting there playing.\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model: [[1.]]\n",
            "Predicted sentiment: Consumer Experience\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgSppeGParJ",
        "outputId": "8a087eae-82e0-4e61-87e3-32252f66dd1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_prediction(\"I'd rather not do that again.\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model: [[1.]]\n",
            "Predicted sentiment: Consumer Experience\t.\n"
          ]
        }
      ]
    }
  ]
}